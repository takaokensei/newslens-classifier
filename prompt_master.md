# üéì PROJECT MASTER PLAN: NewsLens AI (Final Gold Version - C4)

**Role:** Senior ML Engineer & Data Scientist.
**Contexto:** Entrega Final ELE 606 (UFRN).
**Constraint:** Rigorosa ader√™ncia ao **Conjunto C4** + Padr√µes de Produ√ß√£o (Cold Start, Lat√™ncia, Robustez).

-----

### 1\. Vis√£o do Produto & Hip√≥tese Cient√≠fica

**T√≠tulo:** NewsLens AI - Comparative Analysis of Sparse vs. Dense Representations.
**Hip√≥tese Central:** "O ganho sem√¢ntico do BERT (Dense) justifica o aumento de lat√™ncia e custo computacional em compara√ß√£o a um TF-IDF (Sparse) bem ajustado para classifica√ß√£o de not√≠cias?"
**Objetivo:** Um sistema de produ√ß√£o que classifica not√≠cias e quantifica o trade-off entre **Performance (F1/Recall)** e **Efici√™ncia (Infer√™ncia/Mem√≥ria/Cold Start)**.

-----

### ‚öôÔ∏è 2. Arquitetura e Engenharia de Dados

#### **A. Pipeline de Embeddings (Defini√ß√£o T√©cnica)**

  * **E1 - Representa√ß√£o Esparsa (Baseline):**
      * **M√©todo:** TF-IDF (`scipy.sparse`).
      * **Config:** Top 20k features, unigramas + bigramas.
      * **Armazenamento:** `.npz` (Matriz esparsa comprimida).
  * **E2 - Representa√ß√£o Densa (SOTA):**
      * **Modelo:** `neuralmind/bert-base-portuguese-cased`.
      * **Implementa√ß√£o:** Via biblioteca `sentence-transformers` (para garantir pooling otimizado e facilidade de uso).
      * **Estrat√©gia:** **Mean Pooling** autom√°tico da biblioteca.
      * **Armazenamento:** `.npy` (Matriz densa `float32`).

#### **B. Pr√©-processamento de Textos (Fun√ß√£o √önica)**

  * **Fun√ß√£o:** `preprocess_text()` - usada em todo o pipeline (treino, valida√ß√£o, teste, produ√ß√£o).
  * **Etapas:**
      * Lowercase.
      * Remo√ß√£o de caracteres especiais (manter acentos para portugu√™s).
      * Normaliza√ß√£o de espa√ßos em branco.
      * Remo√ß√£o de URLs e emails (opcional, conforme necessidade).
  * **Implementa√ß√£o:** `src/preprocessing.py` com fun√ß√£o reutiliz√°vel.

#### **C. Estrat√©gia de Valida√ß√£o (Requisito Obrigat√≥rio)**

  * **Split Obrigat√≥rio:** **Divis√£o Estratificada em Treino / Valida√ß√£o / Teste** (conforme requisito do professor).
  * **Propor√ß√£o Recomendada:** 60/20/20 (treino/valida√ß√£o/teste) ou 70/15/15, dependendo do tamanho da base.
  * **Implementa√ß√£o:** 
      * Primeiro split: treino+valida√ß√£o (80%) vs teste (20%) - estratificado
      * Segundo split: treino (75% do 80%) vs valida√ß√£o (25% do 80%) - estratificado
      * Resultado final: ~60% treino, ~20% valida√ß√£o, ~20% teste
  * **Uso dos Splits:**
      * **Treino:** Treinar os modelos
      * **Valida√ß√£o:** Ajuste fino de hiperpar√¢metros e sele√ß√£o de modelo (opcional)
      * **Teste:** Avalia√ß√£o final e relat√≥rio (n√£o tocar ap√≥s escolha do modelo)
  * **Safety:** `stratify=y` e `random_state=42` obrigat√≥rios em ambos os splits.

#### **D. Os Modelos**

  * **M1: SVM (Support Vector Machine):** Kernel **Linear** (padr√£o para alta dimens√£o), `class_weight='balanced'`, `probability=True`.
  * **M2: XGBoost:** `n_estimators=100`, `max_depth=6`, `n_jobs=-1` (paralelismo total).

-----

### üß† 3. M√≥dulo de Intelig√™ncia & LLM (Groq API)

#### **Task 3.1: Perfilamento de Classes (H√≠brido)**

  * **Via BERT:** Calcular Centroide dos embeddings -\> Buscar vizinhos mais pr√≥ximos.
  * **Via TF-IDF:** **Chi-Squared Feature Selection**. Identificar os tokens mais correlacionados com a classe (superior √† m√©dia simples).
  * **Output:** JSON "Arqu√©tipos".

#### **Task 3.2: An√°lise Diferencial de Erros**

  * **Filtro:** `(Pred_BERT == Correto) AND (Pred_TFIDF == Incorreto)`.
  * **Prioriza√ß√£o:** Selecionar os **Top-10 casos** com maior delta de confian√ßa.
  * **Prompt:** "O modelo sem√¢ntico (BERT) capturou o contexto, mas o l√©xico (TF-IDF) falhou. Explique qual nuance lingu√≠stica causou isso."

-----

### üìä 4. O "Scoreboard" de Engenharia (Expandido)

O relat√≥rio deve conter **duas** tabelas principais:

**Tabela A: Efici√™ncia & Performance Global**
| Setup | F1-Macro | Acur√°cia | Tempo Treino (s) | **Lat√™ncia (ms/doc)** | **Cold Start (s)** | Tamanho (MB) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| TF-IDF + SVM | ... | ... | ... | ... | ... | ... |
| BERT + XGB | ... | ... | ... | ... | ... | ... |

**Tabela B: Granularidade por Classe (Requisito C4)**

  * Linhas: Classes (Esporte, Pol√≠tica, etc.)
  * Colunas: F1-Score (TF-IDF+SVM), F1-Score (TF-IDF+XGB), F1-Score (BERT+SVM), F1-Score (BERT+XGB).
  * *Meta:* Identificar em quais t√≥picos a sem√¢ntica do BERT √© indispens√°vel.

**Visualiza√ß√µes Obrigat√≥rias:**

  * **Matriz de Confus√£o:** Uma por combina√ß√£o (4 matrizes no total) ou matriz comparativa.
  * **Gr√°ficos de Compara√ß√£o:** F1 por classe (barras agrupadas), Accuracy comparativa, Lat√™ncia vs Performance.

-----

### 5\. Roadmap T√°tico (10 Dias)

**üìç FASE 1: Data Engineering (Dias 1-3)**

  * [x] **Task 1.1:** Setup do `config.py` e estrutura completa de pastas (conforme se√ß√£o 7).
  * [x] **Task 1.2:** `src/preprocessing.py` com fun√ß√£o √∫nica `preprocess_text()`.
  * [x] **Task 1.3:** `data_loader.py` polim√≥rfico (`.npz`/`.npy`).
  * [x] **Task 1.4:** Gerar embeddings BERT via `sentence-transformers` e salvar.
  * [x] **Task 1.5:** **Sanity Check:** Verificar shapes, NaNs e contagem de classes p√≥s-split.

**üìç FASE 2: Training & Benchmarking (Dias 4-5)**

  * [x] **Task 2.1:** Treinar os 4 pares de modelos (TF-IDF+SVM, TF-IDF+XGB, BERT+SVM, BERT+XGB) usando conjunto de TREINO.
  * [x] **Task 2.2:** Avalia√ß√£o no conjunto de VALIDA√á√ÉO para ajuste fino (opcional) e compara√ß√£o inicial.
  * [x] **Task 2.3:** Avalia√ß√£o final no conjunto de TESTE: Accuracy, F1-Macro, F1 por classe, Matriz de Confus√£o (4 matrizes).
  * [x] **Task 2.4:** Script de benchmark: medir infer√™ncia com `batch_size=1` (simula√ß√£o real).
  * [x] **Task 2.5:** Gerar Tabela A (Efici√™ncia) e Tabela B (Classes) + visualiza√ß√µes.

**üìç FASE 3: AI Analysis & Dashboard (Dias 6-8)**

  * [x] **Task 3.1:** Pipeline de Prot√≥tipos (Chi-Squared + Centroides) para perfilamento de classes.
  * [x] **Task 3.2:** Pipeline LLM Diferencial (max 10 calls) para an√°lise de erros.
  * [x] **Task 3.3:** Sistema de Logs: implementar `log_prediction()` e `logs/predicoes.csv`.
  * [x] **Task 3.4:** Script de Produ√ß√£o: `scripts/processar_novos.py` para classificar textos em `data/novos/`.
  * [x] **Task 3.5:** Streamlit com 2 p√°ginas principais:
      * **Tab 1 - "Classifica√ß√£o":** Entrada de texto ‚Üí Classe predita, Score, Explica√ß√£o (via LLM).
      * **Tab 2 - "Monitoramento":** Dashboard com gr√°ficos de logs (contagem por classe, evolu√ß√£o temporal, estat√≠sticas).

**üìç FASE 4: Consolida√ß√£o (Dias 9-10)**

  * [x] **Task 4.1:** Escrita do relat√≥rio (10-20 p√°ginas) com estrutura completa (se√ß√£o 8).
      * ‚úÖ Template LaTeX criado (`reports/relatorio.tex`)
      * ‚úÖ Todas as se√ß√µes estruturadas conforme se√ß√£o 8
      * ‚úÖ Dados reais preenchidos nas tabelas
      * ‚úÖ An√°lises detalhadas inclu√≠das
      * ‚ö†Ô∏è **Pendente:** Compila√ß√£o final do PDF (usu√°rio far√° via Streamlit ou Overleaf)
  * [x] **Task 4.2:** Prepara√ß√£o da apresenta√ß√£o PPT (10-15 minutos).
      * ‚úÖ Prompt completo criado para Gamma AI (`reports/prompt_gamma_ai.md`)
      * ‚úÖ 20 slides estruturados com todo o conte√∫do
      * ‚úÖ Dados reais inclu√≠dos
      * ‚ö†Ô∏è **Pendente:** Gera√ß√£o no Gamma AI (usu√°rio far√°)
  * [x] **Task 4.3:** Testes finais do Streamlit e valida√ß√£o do ambiente de produ√ß√£o.
      * ‚úÖ Script de valida√ß√£o criado (`scripts/test_production.py`)
      * ‚úÖ Todos os testes passando
      * ‚úÖ Bug de truncamento de explica√ß√£o LLM corrigido
      * ‚úÖ Sistema funcional e validado
  * [x] **Task 4.4:** Documenta√ß√£o final: `README.md` com instru√ß√µes de instala√ß√£o e execu√ß√£o.
      * ‚úÖ README completo e profissional
      * ‚úÖ Instru√ß√µes detalhadas de instala√ß√£o
      * ‚úÖ Documenta√ß√£o de uso e estrutura
      * ‚úÖ M√©tricas e resultados atualizados

-----

### 6\. Estrutura de Pastas (Organiza√ß√£o do Projeto)

```
newslens-classifier/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Base original de not√≠cias (6 classes)
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Dados pr√©-processados
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/       # Embeddings salvos (.npz para TF-IDF, .npy para BERT)
‚îÇ   ‚îî‚îÄ‚îÄ novos/            # Novos textos para simula√ß√£o de produ√ß√£o (OBRIGAT√ìRIO)
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ predicoes.csv     # Log de todas as predi√ß√µes (OBRIGAT√ìRIO)
‚îú‚îÄ‚îÄ models/               # Modelos treinados salvos (.pkl ou .joblib)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py         # Configura√ß√µes centralizadas
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py  # Fun√ß√£o √∫nica de pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py    # Carregamento polim√≥rfico de dados
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py     # Gera√ß√£o de embeddings (TF-IDF e BERT)
‚îÇ   ‚îú‚îÄ‚îÄ train.py          # Script de treinamento
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py       # Script de avalia√ß√£o e m√©tricas
‚îÇ   ‚îî‚îÄ‚îÄ llm_analysis.py   # Integra√ß√£o com Groq API
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ processar_novos.py # Script para classificar textos em data/novos/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îî‚îÄ‚îÄ app_streamlit.py  # Aplica√ß√£o Streamlit principal
‚îú‚îÄ‚îÄ tools/                # Scripts auxiliares (se necess√°rio)
‚îú‚îÄ‚îÄ notebooks/            # Jupyter notebooks para an√°lise explorat√≥ria
‚îú‚îÄ‚îÄ requirements.txt      # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md             # Documenta√ß√£o e instru√ß√µes
```

### 7\. Sistema de Logs e Monitoramento

#### **A. Formato do Log (`logs/predicoes.csv`)**

Colunas obrigat√≥rias:
  * `timestamp`: Data e hora da predi√ß√£o
  * `texto`: Texto original (ou hash se muito longo)
  * `classe_predita`: Classe retornada pelo modelo
  * `score`: Score/confian√ßa da predi√ß√£o
  * `embedding_usado`: "TF-IDF" ou "BERT"
  * `modelo_usado`: "SVM" ou "XGBoost"
  * `fonte`: "streamlit" ou "script_producao"

#### **B. Fun√ß√£o de Log**

```python
def log_prediction(texto, classe_predita, score, embedding_usado, modelo_usado, fonte="streamlit"):
    """Registra predi√ß√£o no arquivo logs/predicoes.csv"""
    # Implementa√ß√£o com pandas.to_csv(mode='a') ou similar
```

#### **C. Script de Produ√ß√£o (`scripts/processar_novos.py`)**

  * **Objetivo:** Classificar todos os textos em `data/novos/` e registrar em logs.
  * **Funcionalidades:**
      * Ler todos os arquivos de texto em `data/novos/`.
      * Aplicar pr√©-processamento.
      * Classificar com os 4 modelos (ou modelo escolhido).
      * Registrar cada predi√ß√£o em `logs/predicoes.csv`.
      * Gerar relat√≥rio resumido.

### 8\. Interface Streamlit (`apps/app_streamlit.py`)

#### **Estrutura da Aplica√ß√£o:**

  * **Sidebar:** Instru√ß√µes de uso e sele√ß√£o de modelo/embedding.
  * **Tab 1 - "Classifica√ß√£o":**
      * Caixa de texto para entrada.
      * Bot√£o "Classificar".
      * Exibi√ß√£o de resultados:
          * Classe predita (destaque visual).
          * Score/confian√ßa.
          * Explica√ß√£o via LLM ("Por que este texto foi classificado como X?").
      * Op√ß√£o de salvar predi√ß√£o (registra em log).
  * **Tab 2 - "Monitoramento":**
      * Leitura de `logs/predicoes.csv`.
      * Gr√°ficos:
          * Contagem de predi√ß√µes por classe (bar chart).
          * Evolu√ß√£o temporal (line chart).
          * Distribui√ß√£o de scores (histograma).
          * Estat√≠sticas simples (total de predi√ß√µes, classe mais frequente, etc.).
      * Filtros por data, modelo, embedding.

### 9\. Configura√ß√£o T√©cnica (`src/config.py`)

```python
import os

# 1. Configura√ß√£o de Dados
DATA_CONFIG = {
    'test_size': 0.2,           # Primeiro split: 20% para teste
    'val_size': 0.25,           # Segundo split: 25% do restante para valida√ß√£o
    'stratify': True,           # CR√çTICO: Manter distribui√ß√£o original
    'random_state': 42          # Reproduzibilidade
}

# 2. Features e Embeddings
FEATURE_CONFIG = {
    'tfidf': {
        'max_features': 20000,
        'ngram_range': (1, 2),
        'storage': 'sparse_npz'
    },
    'bert': {
        'model_name': 'neuralmind/bert-base-portuguese-cased',
        'implementation': 'sentence-transformers', # Biblioteca definida
        'pooling': 'mean',                         # Estrat√©gia definida
        'batch_size': 32,
        'storage': 'dense_npy'
    }
}

# 3. Modelos
MODELS_CONFIG = {
    'svm': {
        'kernel': 'linear',
        'class_weight': 'balanced',
        'probability': True
    },
    'xgboost': {
        'n_estimators': 100,
        'max_depth': 6,
        'n_jobs': -1
    }
}

# 4. Limites de API (Controle de Custo)
LLM_CONFIG = {
    'provider': 'groq',
    'model': 'llama-3.1-70b-versatile',
    'max_examples_differential': 10,  # Hard limit
    'api_key': os.getenv('GROQ_API_KEY')  # Vari√°vel de ambiente
}

# 5. Caminhos de Pastas
PATHS = {
    'data_raw': 'data/raw',
    'data_processed': 'data/processed',
    'data_embeddings': 'data/embeddings',
    'data_novos': 'data/novos',
    'logs': 'logs',
    'models': 'models'
}
```

-----

### 10\. Estrutura do Relat√≥rio (PDF - 10 a 20 p√°ginas)

#### **Se√ß√µes Obrigat√≥rias:**

1. **Introdu√ß√£o**
   * Objetivo do trabalho
   * Hip√≥tese cient√≠fica central
   * Contexto e motiva√ß√£o

2. **Descri√ß√£o da Base de Dados**
   * Caracter√≠sticas da base (6 classes de not√≠cias)
   * Estat√≠sticas descritivas (distribui√ß√£o de classes, tamanho m√©dio de textos)
   * Pr√©-processamento aplicado

3. **M√©todos e Pipeline**
   * Embeddings utilizados (TF-IDF e BERT) - detalhamento t√©cnico
   * Modelos de classifica√ß√£o (SVM e XGBoost) - hiperpar√¢metros
   * Estrat√©gia de valida√ß√£o (divis√£o treino/valida√ß√£o/teste estratificada)
   * Uso de LLMs (perfilamento de classes e an√°lise de erros)

4. **Experimentos e Resultados**
   * Tabela A: Efici√™ncia & Performance Global
   * Tabela B: Granularidade por Classe
   * Matrizes de Confus√£o (4 combina√ß√µes)
   * Gr√°ficos comparativos (F1 por classe, Accuracy, Lat√™ncia vs Performance)
   * An√°lise de trade-offs (Performance vs Efici√™ncia)

5. **Uso de LLMs**
   * Perfilamento de classes (exemplos de arqu√©tipos gerados)
   * An√°lise diferencial de erros (casos analisados)
   * Discuss√£o sobre o valor agregado das explica√ß√µes

6. **Sistema de Produ√ß√£o e Monitoramento**
   * Arquitetura do sistema Streamlit
   * Sistema de logs implementado
   * Exemplos de uso em produ√ß√£o (textos de `data/novos/`)
   * Dashboard de monitoramento (screenshots e an√°lise)

7. **Discuss√£o**
   * Compara√ß√£o entre embeddings (TF-IDF vs BERT)
   * Compara√ß√£o entre modelos (SVM vs XGBoost)
   * Resposta √† hip√≥tese cient√≠fica: quando o BERT justifica o custo?
   * Limita√ß√µes e trabalhos futuros

8. **Conclus√µes**
   * Principais achados
   * Contribui√ß√µes do trabalho
   * Recomenda√ß√µes pr√°ticas

9. **Refer√™ncias**
   * Artigos, bibliotecas e recursos utilizados

### 11\. Entreg√°veis Finais

#### **Obrigat√≥rios:**

1. **Reposit√≥rio GitHub ou Google Drive:**
   * C√≥digo completo e organizado (src/, apps/, tools/, data/, logs/)
   * `requirements.txt` atualizado
   * `README.md` com instru√ß√µes de instala√ß√£o e execu√ß√£o
   * Estrutura de pastas conforme se√ß√£o 6

2. **Relat√≥rio PDF (10-20 p√°ginas):**
   * Estrutura conforme se√ß√£o 10
   * Tabelas e gr√°ficos de qualidade
   * An√°lise cr√≠tica dos resultados

3. **Apresenta√ß√£o PPT (10-15 minutos):**
   * Objetivo e hip√≥tese cient√≠fica
   * Arquitetura da solu√ß√£o
   * Principais resultados (tabelas e gr√°ficos)
   * Demonstra√ß√£o do Streamlit (screenshots ou v√≠deo)
   * Coment√°rios sobre comportamento em produ√ß√£o

4. **Sistema Funcional:**
   * Streamlit rodando localmente (`streamlit run apps/app_streamlit.py`)
   * Script de produ√ß√£o funcionando
   * Logs sendo gerados corretamente

-----

### Pr√≥ximo Passo

Como Engenheiro S√™nior, recomendo iniciarmos pela **Task 1.1, 1.2 e 1.3**:
1. Criar estrutura completa de pastas
2. Implementar `src/preprocessing.py` com fun√ß√£o √∫nica
3. Implementar `src/config.py` com todas as configura√ß√µes
4. Implementar `src/data_loader.py` com carregamento polim√≥rfico